{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('64/.DS_Store'), PosixPath('64/notwaldo'), PosixPath('64/waldo')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_dir = \"64\"\n",
    "dir_list = [x for x in Path(root_dir).iterdir()]\n",
    "\n",
    "labels = [x.name for x in dir_list if '.' not in x.name] \n",
    "\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through to get Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_size = (64,64)\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5376 files belonging to 2 classes.\n",
      "Using 4301 files for training.\n",
      "Found 5376 files belonging to 2 classes.\n",
      "Using 1075 files for validation.\n"
     ]
    }
   ],
   "source": [
    "##(X_train, y_train) filepath = \"../Images/test2.png\"\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "X_train = []\n",
    "y_train = []\n",
    "waldo_images = []\n",
    "first = 1\n",
    "second = 0\n",
    "third = 0\n",
    "\n",
    "images = image_dataset_from_directory(\n",
    "  Path('64'),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=42,\n",
    "  image_size=(image_size),\n",
    "  batch_size=32)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  Path('64'),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=42,\n",
    "  image_size=(image_size),\n",
    "  batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notwaldo', 'waldo']\n"
     ]
    }
   ],
   "source": [
    "class_names = images.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is common\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(64, 64, 3)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation=\"relu\", input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second, hidden layer\n",
    "model.add(layers.MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(layers.Conv2D(128,(3,3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,681,474\n",
      "Trainable params: 1,681,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "135/135 - 22s - loss: 0.0699 - accuracy: 0.9851 - val_loss: 0.0626 - val_accuracy: 0.9935\n",
      "Epoch 2/10\n",
      "135/135 - 21s - loss: 0.0533 - accuracy: 0.9926 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 3/10\n",
      "135/135 - 21s - loss: 0.0517 - accuracy: 0.9926 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "135/135 - 21s - loss: 0.0490 - accuracy: 0.9926 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "135/135 - 22s - loss: 0.0471 - accuracy: 0.9926 - val_loss: 0.0411 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "135/135 - 22s - loss: 0.0505 - accuracy: 0.9926 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 7/10\n",
      "135/135 - 23s - loss: 0.0451 - accuracy: 0.9926 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 8/10\n",
      "135/135 - 23s - loss: 0.0439 - accuracy: 0.9926 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "135/135 - 22s - loss: 0.0428 - accuracy: 0.9926 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 10/10\n",
      "135/135 - 22s - loss: 0.0634 - accuracy: 0.9926 - val_loss: 0.0375 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f995e36ddd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(images, epochs=10, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"waldo_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"waldo_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 2s - loss: 0.0375 - accuracy: 0.9935\n",
      "Loss: 0.03749001771211624, Accuracy: 0.9934883713722229\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(val_ds, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Test of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"64/waldo/18_2_15.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_size = (64,64)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"rgb\")\n",
    "im\n",
    "from keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "img = image.flatten().reshape(-1, 64*64)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = 1 - img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 2s - loss: 0.0375 - accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03749001771211624, 0.9934883713722229]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_images, test_labels = val_ds\n",
    "model.evaluate(val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to notwaldo with a 98.87 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "#sunflower_path = tf.keras.utils.get_file('128/waldo/13_2_1.jpg')\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    Path('64/waldo/4_2_12.jpg'), target_size=(64,64)\n",
    ")\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
