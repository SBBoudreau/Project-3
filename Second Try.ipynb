{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('dataset/Zapdos'), PosixPath('dataset/Kadabra'), PosixPath('dataset/Omanyte'), PosixPath('dataset/Shellder'), PosixPath('dataset/Bellsprout'), PosixPath('dataset/Eevee'), PosixPath('dataset/Jolteon'), PosixPath('dataset/Hypno'), PosixPath('dataset/Seel'), PosixPath('dataset/Zubat'), PosixPath('dataset/Graveler'), PosixPath('dataset/Magneton'), PosixPath('dataset/Abra'), PosixPath('dataset/Kingler'), PosixPath('dataset/Alakazam'), PosixPath('dataset/Clefable'), PosixPath('dataset/Gyarados'), PosixPath('dataset/Poliwag'), PosixPath('dataset/Rapidash'), PosixPath('dataset/Machamp'), PosixPath('dataset/Pinsir'), PosixPath('dataset/Muk'), PosixPath('dataset/Seaking'), PosixPath('dataset/Magikarp'), PosixPath('dataset/Goldeen'), PosixPath('dataset/Venusaur'), PosixPath('dataset/Flareon'), PosixPath('dataset/Jigglypuff'), PosixPath('dataset/Doduo'), PosixPath('dataset/Weedle'), PosixPath('dataset/Vileplume'), PosixPath('dataset/Arcanine'), PosixPath('dataset/Tentacruel'), PosixPath('dataset/Gloom'), PosixPath('dataset/Charmeleon'), PosixPath('dataset/Articuno'), PosixPath('dataset/Sandshrew'), PosixPath('dataset/Spearow'), PosixPath('dataset/Marowak'), PosixPath('dataset/Clefairy'), PosixPath('dataset/Snorlax'), PosixPath('dataset/Scyther'), PosixPath('dataset/Primeape'), PosixPath('dataset/Diglett'), PosixPath('dataset/Onix'), PosixPath('dataset/Mankey'), PosixPath('dataset/Rattata'), PosixPath('dataset/Voltorb'), PosixPath('dataset/Gengar'), PosixPath('dataset/Gastly'), PosixPath('dataset/Cloyster'), PosixPath('dataset/Weepinbell'), PosixPath('dataset/Dragonair'), PosixPath('dataset/Squirtle'), PosixPath('dataset/Pikachu'), PosixPath('dataset/Victreebel'), PosixPath('dataset/Charmander'), PosixPath('dataset/Staryu'), PosixPath('dataset/Venonat'), PosixPath('dataset/Vaporeon'), PosixPath('dataset/Ivysaur'), PosixPath('dataset/Krabby'), PosixPath('dataset/Drowzee'), PosixPath('dataset/Sandslash'), PosixPath('dataset/Kangaskhan'), PosixPath('dataset/Chansey'), PosixPath('dataset/Butterfree'), PosixPath('dataset/Starmie'), PosixPath('dataset/Magmar'), PosixPath('dataset/Beedrill'), PosixPath('dataset/Ninetales'), PosixPath('dataset/Magnemite'), PosixPath('dataset/Metapod'), PosixPath('dataset/Electrode'), PosixPath('dataset/Raichu'), PosixPath('dataset/Fearow'), PosixPath('dataset/Mewtwo'), PosixPath('dataset/Kabuto'), PosixPath('dataset/Pidgeotto'), PosixPath('dataset/Hitmonchan'), PosixPath('dataset/Blastoise'), PosixPath('dataset/Weezing'), PosixPath('dataset/Golbat'), PosixPath('dataset/Seadra'), PosixPath('dataset/Rhyhorn'), PosixPath('dataset/Moltres'), PosixPath('dataset/Golduck'), PosixPath('dataset/Kabutops'), PosixPath('dataset/Aerodactyl'), PosixPath('dataset/Haunter'), PosixPath('dataset/Machop'), PosixPath('dataset/Koffing'), PosixPath('dataset/Pidgeot'), PosixPath('dataset/Wigglytuff'), PosixPath('dataset/Porygon'), PosixPath('dataset/Vulpix'), PosixPath('dataset/Dugtrio'), PosixPath('dataset/Ditto'), PosixPath('dataset/Raticate'), PosixPath('dataset/Geodude'), PosixPath('dataset/Tentacool'), PosixPath('dataset/Horsea'), PosixPath('dataset/Oddish'), PosixPath('dataset/Machoke'), PosixPath('dataset/Lapras'), PosixPath('dataset/Poliwrath'), PosixPath('dataset/Omastar'), PosixPath('dataset/Slowpoke'), PosixPath('dataset/Bulbasaur'), PosixPath('dataset/Growlithe'), PosixPath('dataset/Ponyta'), PosixPath('dataset/Parasect'), PosixPath('dataset/Dodrio'), PosixPath('dataset/Meowth'), PosixPath('dataset/Exeggutor'), PosixPath('dataset/Persian'), PosixPath('dataset/Psyduck'), PosixPath('dataset/Tauros'), PosixPath('dataset/Pidgey'), PosixPath('dataset/Electabuzz'), PosixPath('dataset/Dewgong'), PosixPath('dataset/Wartortle'), PosixPath('dataset/Nidoking'), PosixPath('dataset/Grimer'), PosixPath('dataset/Ekans'), PosixPath('dataset/Caterpie'), PosixPath('dataset/Tangela'), PosixPath('dataset/Kakuna'), PosixPath('dataset/Golem'), PosixPath('dataset/Slowbro'), PosixPath('dataset/MrMime'), PosixPath('dataset/Jynx'), PosixPath('dataset/Mew'), PosixPath('dataset/Paras'), PosixPath('dataset/Hitmonlee'), PosixPath('dataset/Exeggcute'), PosixPath('dataset/Arbok'), PosixPath('dataset/Venomoth'), PosixPath('dataset/Dratini'), PosixPath('dataset/Cubone'), PosixPath('dataset/Rhydon'), PosixPath('dataset/Dragonite'), PosixPath('dataset/Nidorino'), PosixPath('dataset/Lickitung'), PosixPath('dataset/Nidorina'), PosixPath('dataset/Charizard'), PosixPath('dataset/Poliwhirl'), PosixPath('dataset/Nidoqueen'), PosixPath('dataset/Farfetchd')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_dir = \"dataset\"\n",
    "dir_list = [x for x in Path(root_dir).iterdir()]\n",
    "\n",
    "labels = [x.name for x in dir_list if '.' not in x.name] \n",
    "\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through to get Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_size = (128,128)\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10658 files belonging to 149 classes.\n",
      "Using 8527 files for training.\n",
      "Found 10658 files belonging to 149 classes.\n",
      "Using 2131 files for validation.\n"
     ]
    }
   ],
   "source": [
    "##(X_train, y_train) filepath = \"../Images/test2.png\"\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "X_train = []\n",
    "y_train = []\n",
    "waldo_images = []\n",
    "first = 1\n",
    "second = 0\n",
    "third = 0\n",
    "\n",
    "images = image_dataset_from_directory(\n",
    "  Path('dataset'),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=42,\n",
    "  image_size=(image_size),\n",
    "  batch_size=32)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  Path('dataset'),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=42,\n",
    "  image_size=(image_size),\n",
    "  batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "class_names = images.class_names\n",
    "num=len(class_names)\n",
    "print(len(class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is common\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(128, 128, 3)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation=\"relu\", input_shape=(128,128,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second, hidden layer\n",
    "model.add(layers.MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# data_augmentation = keras.Sequential(\n",
    "#   [\n",
    "#     layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "#                                                  input_shape=(128, \n",
    "#                                                               128,\n",
    "#                                                               3)),\n",
    "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#     layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "#   ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "#model.add(data_augmentation)\n",
    "model.add(layers.Conv2D(128,(3,3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 126, 126, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                7372864   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 149)               9685      \n",
      "=================================================================\n",
      "Total params: 7,533,717\n",
      "Trainable params: 7,533,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "267/267 - 322s - loss: 4.8728 - accuracy: 0.0532 - val_loss: 4.6410 - val_accuracy: 0.0863\n",
      "Epoch 2/10\n",
      "267/267 - 314s - loss: 4.4370 - accuracy: 0.0910 - val_loss: 4.3251 - val_accuracy: 0.1145\n",
      "Epoch 3/10\n",
      "267/267 - 327s - loss: 3.9472 - accuracy: 0.1554 - val_loss: 4.2634 - val_accuracy: 0.1427\n",
      "Epoch 4/10\n",
      "267/267 - 828s - loss: 3.2140 - accuracy: 0.2805 - val_loss: 4.3692 - val_accuracy: 0.1656\n",
      "Epoch 5/10\n",
      "267/267 - 293s - loss: 2.4145 - accuracy: 0.4347 - val_loss: 4.7491 - val_accuracy: 0.1966\n",
      "Epoch 6/10\n",
      "267/267 - 1092s - loss: 1.7219 - accuracy: 0.5742 - val_loss: 5.7308 - val_accuracy: 0.1886\n",
      "Epoch 7/10\n",
      "267/267 - 2931s - loss: 1.2051 - accuracy: 0.7006 - val_loss: 6.4544 - val_accuracy: 0.1807\n",
      "Epoch 8/10\n",
      "267/267 - 17018s - loss: 0.8631 - accuracy: 0.7827 - val_loss: 7.2792 - val_accuracy: 0.1905\n",
      "Epoch 9/10\n",
      "267/267 - 17888s - loss: 0.6669 - accuracy: 0.8309 - val_loss: 8.1661 - val_accuracy: 0.1703\n",
      "Epoch 10/10\n",
      "267/267 - 4525s - loss: 0.5275 - accuracy: 0.8688 - val_loss: 9.1396 - val_accuracy: 0.1807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2595aec90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(images, epochs=10, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"pokemon_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"pokemon_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 - 31s - loss: 9.1396 - accuracy: 0.1807\n",
      "Loss: 9.139617919921875, Accuracy: 0.18066635727882385\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(val_ds, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Test of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images, test_labels = val_ds\n",
    "model.evaluate(val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to Ponyta with a 10.63 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#sunflower_url = \"https://cdn.bulbagarden.net/upload/archive/e/e2/20130904133327%21133Eevee.png\"\n",
    "#sunflower_path = tf.keras.utils.get_file('128/waldo/13_2_1.jpg')\n",
    "#Path('dataset/Pidgeot/988f8c3307ca4a55a47e940681f63059.jpg')\n",
    "#.jpg\n",
    "#sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    Path('dataset/Pidgeot/988f8c3307ca4a55a47e940681f63059.jpg'), target_size=(128,128)\n",
    ")\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
